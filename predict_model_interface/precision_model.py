#!/usr/bin/python
# -*- coding: utf-8 -*-


from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
import matplotlib.pyplot as plt
import numpy as np
import itertools

#准确度模型
def get_metrics(y_test, y_predicted):
	# true positives / (true positives+false positives)
	precision = precision_score(y_test, y_predicted, pos_label=None,
								average='weighted')
	# true positives / (true positives + false negatives)
	recall = recall_score(y_test, y_predicted, pos_label=None,
						  average='weighted')

	# harmonic mean of precision and recall
	f1 = f1_score(y_test, y_predicted, pos_label=None, average='weighted')

	# true positives + true negatives/ total
	accuracy = accuracy_score(y_test, y_predicted)
	return accuracy, precision, recall, f1


#混淆矩阵
def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.winter):
	if normalize:
		cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
	plt.imshow(cm, interpolation='nearest', cmap=cmap)
	plt.title(title, fontsize=30)
	plt.colorbar()
	tick_marks = np.arange(len(classes))
	plt.xticks(tick_marks, classes, fontsize=20)
	plt.yticks(tick_marks, classes, fontsize=20)
	fmt = '.2f' if normalize else 'd'
	thresh = cm.max() / 2.
	for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
		plt.text(j, i, format(cm[i, j], fmt), horizontalalignment="center",
				 color="white" if cm[i, j] < thresh else "black", fontsize=40)

	plt.tight_layout()
	plt.ylabel('True label', fontsize=30)
	plt.xlabel('Predicted label', fontsize=30)

	return plt
#分割数据
def fen_ge(sentences):
	x,y=zip(*sentences)
	return x,y



